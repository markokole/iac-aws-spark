---
- hosts: spark-master
  vars:
    spark_home:  "/usr/spark/spark-2.4.0-bin-hadoop2.7"
  tasks:

    - name: Add spark to centos
      user:
        name: spark
        groups: centos
        append: yes
      become: yes

    - name: Download Anaconda
      get_url:
        url: https://repo.anaconda.com/archive/Anaconda3-5.3.1-Linux-x86_64.sh
        dest: /tmp

    - name: Create Spark Log directory
      file:
        path: /var/log/spark/apps
        owner: spark
        group: spark
        state: directory
        mode: 0777
        recurse: yes
      become: yes

    - name: Chmod Anaconda installation file
      file:
        path: /tmp/Anaconda3-5.3.1-Linux-x86_64.sh
        mode: 0775
      become: yes

    - name: Start Anaconda installation
      command: /tmp/Anaconda3-5.3.1-Linux-x86_64.sh -b -p /usr/anaconda
      become: yes

    - name: Printing the environmentâ€‹ variable in Spark
      debug:
        msg: "{{ spark_home }}"

    - name: Create file spark-defaults.conf
      command: sh -c "echo {{ item }} >> {{ spark_home }}/conf/spark-defaults.conf"
      with_items:
        - spark.history.fs.logDirectory file:///var/log/spark/apps
        - spark.eventLog.dir file:///var/log/spark/apps
        - spark.eventLog.enabled true
      become: yes
      become_user: spark

    - name: Start Spark History Server
      command: sh {{ spark_home }}/sbin/start-history-server.sh
      become: yes
      become_user: spark

    - name: Start Spark Master
      command: sh {{ spark_home }}/sbin/start-master.sh
      become: yes
      become_user: spark
